{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yzvWMReL2G7j","executionInfo":{"status":"ok","timestamp":1749677917350,"user_tz":-120,"elapsed":24660,"user":{"displayName":"Daniel Linfon Ye Liu","userId":"04630746813985450145"}},"outputId":"a233e073-d324-4f97-889f-5befb1b589aa"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -q transformers scikit-learn datasets evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5_5SEmZwfnd","executionInfo":{"status":"ok","timestamp":1749677934737,"user_tz":-120,"elapsed":17389,"user":{"displayName":"Daniel Linfon Ye Liu","userId":"04630746813985450145"}},"outputId":"2cb22c4b-8a9c-4dc2-c8ad-544c1c560aae"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import json\n","import re\n","\n","# üî¢ Preprocesamiento y m√©tricas\n","from sklearn.preprocessing import LabelEncoder\n","import evaluate\n","\n","# üìö Carga de datasets\n","import pandas as pd\n","from datasets import Dataset, DatasetDict, load_dataset\n","\n","\n","# Modelos y entrenamiento con Hugging Face\n","from transformers import (\n","    T5ForConditionalGeneration,\n","    T5TokenizerFast,\n","    T5Config,\n","    Trainer,\n","    TrainingArguments,\n","    DataCollatorForSeq2Seq,\n","    EarlyStoppingCallback,\n",")\n","\n","# üî• PyTorch\n","import torch\n","from torch.utils.data import DataLoader"],"metadata":{"id":"zRbZ55rV-LeE","executionInfo":{"status":"ok","timestamp":1749677983116,"user_tz":-120,"elapsed":48383,"user":{"displayName":"Daniel Linfon Ye Liu","userId":"04630746813985450145"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQ62JQtL1_4W","executionInfo":{"status":"ok","timestamp":1749550828505,"user_tz":-120,"elapsed":39973,"user":{"displayName":"Daniel Linfon Ye Liu","userId":"04630746813985450145"}},"outputId":"d47b0189-707b-4e11-dcbc-9bacdebc6458"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/TFG/models/finetuned_t5-small_eval_loss/ and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"]},{"output_type":"stream","name":"stdout","text":["Frase: 'Add this song to my playlist' ‚Üí Predicci√≥n: add\n","Frase: 'Could you remove this track?' ‚Üí Predicci√≥n: add\n","Frase: 'Show me my current playlist' ‚Üí Predicci√≥n: add\n","Frase: 'Clear the entire playlist' ‚Üí Predicci√≥n: add\n","Frase: 'Add this song to my playlist' ‚Üí Predicci√≥n: add\n","Frase: 'Remove this track from my list' ‚Üí Predicci√≥n: add\n","Frase: 'Show me my current playlist' ‚Üí Predicci√≥n: add\n","Frase: 'Clear my entire playlist' ‚Üí Predicci√≥n: add\n","Frase: 'Could you please delete all the songs?' ‚Üí Predicci√≥n: add\n","Frase: 'Can you add a song to my playlist?' ‚Üí Predicci√≥n: clear\n","Frase: 'I'd like to see what songs I have added' ‚Üí Predicci√≥n: add\n","Frase: 'Take this song out of my list' ‚Üí Predicci√≥n: add\n","Frase: 'Hey, can u clear my playlist' ‚Üí Predicci√≥n: add\n","Frase: 'can u delete the song Crazy' ‚Üí Predicci√≥n: add\n"]}],"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","import torch\n","import numpy as np\n","\n","# Cargar los tres modelos y tokenizadores\n","modelo_bert_path = \"/content/drive/MyDrive/TFG/models/finetuned_bert-base-uncased_loss/\"\n","modelo_roberta_path = \"/content/drive/MyDrive/TFG/models/finetuned_roberta-base_loss/\"\n","modelo_t5_path = \"/content/drive/MyDrive/TFG/models/finetuned_t5-small_eval_loss/\"\n","\n","modelo_bert = AutoModelForSequenceClassification.from_pretrained(modelo_bert_path)\n","tokenizer_bert = AutoTokenizer.from_pretrained(modelo_bert_path)\n","\n","modelo_roberta = AutoModelForSequenceClassification.from_pretrained(modelo_roberta_path)\n","tokenizer_roberta = AutoTokenizer.from_pretrained(modelo_roberta_path)\n","\n","modelo_t5 = AutoModelForSequenceClassification.from_pretrained(modelo_t5_path)\n","tokenizer_t5 = AutoTokenizer.from_pretrained(modelo_t5_path)\n","\n","# Frases de prueba\n","frases_prueba = [\n","    \"Add this song to my playlist\",  # ADD\n","    \"Could you remove this track?\",  # REMOVE\n","    \"Show me my current playlist\",  # VIEW\n","    \"Clear the entire playlist\",    # CLEAR\n","    \"Add this song to my playlist\",  # ADD\n","    \"Remove this track from my list\",  # REMOVE\n","    \"Show me my current playlist\",  # VIEW\n","    \"Clear my entire playlist\",  # CLEAR\n","    \"Could you please delete all the songs?\",  # CLEAR\n","    \"Can you add a song to my playlist?\",  # ADD\n","    \"I'd like to see what songs I have added\",  # VIEW\n","    \"Take this song out of my list\",  # REMOVE\n","    \"Hey, can u clear my playlist\",     # CLEAR\n","    \"can u delete the song Crazy\",   # REMOVE\n","]\n","\n","# Tokenizar las frases con los tres tokenizadores\n","inputs_bert = tokenizer_bert(frases_prueba, padding=True, truncation=True, return_tensors=\"pt\")\n","inputs_roberta = tokenizer_roberta(frases_prueba, padding=True, truncation=True, return_tensors=\"pt\")\n","inputs_t5 = tokenizer_t5(frases_prueba, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","# Obtener las predicciones de los tres modelos\n","def get_predictions(model, inputs):\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        return torch.argmax(outputs.logits, dim=1).numpy()\n","\n","predicciones_bert = get_predictions(modelo_bert, inputs_bert)\n","predicciones_roberta = get_predictions(modelo_roberta, inputs_roberta)\n","predicciones_t5 = get_predictions(modelo_t5, inputs_t5)\n","\n","# Promediar las predicciones de los tres modelos\n","# En lugar de tomar la predicci√≥n de cada modelo por separado, tomamos el promedio de las predicciones\n","# para cada clase y luego asignamos la clase con mayor puntuaci√≥n.\n","predicciones_ensemble = np.argmax(np.stack([predicciones_bert, predicciones_roberta, predicciones_t5], axis=0), axis=0)\n","\n","# Etiquetas correspondientes a las predicciones\n","etiquetas = [\"add\", \"clear\", \"remove\", \"view\"]\n","\n","# Mostrar los resultados\n","for frase, pred in zip(frases_prueba, predicciones_ensemble):\n","    print(f\"Frase: '{frase}' ‚Üí Predicci√≥n: {etiquetas[pred]}\")\n","\n"]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","import torch\n","\n","# Cargar el modelo y el tokenizador desde el directorio guardado\n","model_path = \"/content/drive/MyDrive/TFG/models/finetuned_bert-base-uncased_loss\"\n","modelo = AutoModelForSequenceClassification.from_pretrained(model_path)\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","# Definir frases de prueba\n","frases_prueba = [\n","    \"Add this song to my playlist\",  # ADD\n","    \"Could you remove this track?\",  # REMOVE\n","    \"Show me my current playlist\",  # VIEW\n","    \"Clear the entire playlist\",    # CLEAR\n","    \"Add this song to my playlist\",  # ADD\n","    \"Remove this track from my list\",  # REMOVE\n","    \"Show me my current playlist\",  # VIEW\n","    \"Clear my entire playlist\",  # CLEAR\n","    \"Could you please delete all the songs?\",  # CLEAR\n","    \"Can you add a song to my playlist?\",  # ADD\n","    \"I'd like to see what songs I have added\",  # VIEW\n","    \"Take this song out of my list\",  # REMOVE\n","    \"Hey, can u clear my playlist\",     # CLEAR\n","    \"can u delete the song Crazy\",   # REMOVE\n","]\n","\n","# Tokenizar las frases de prueba\n","inputs = tokenizer(frases_prueba, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","# Pasar las frases al modelo para obtener predicciones\n","modelo.eval()  # Poner el modelo en modo evaluaci√≥n\n","with torch.no_grad():\n","    outputs = modelo(**inputs)\n","\n","# Convertir los logits a predicciones\n","predicciones = torch.argmax(outputs.logits, dim=1).numpy()\n","\n","# Mapear los √≠ndices a las etiquetas\n","etiquetas = [\"add\", \"clear\", \"remove\", \"view\"]\n","\n","# Mostrar las predicciones\n","for frase, pred in zip(frases_prueba, predicciones):\n","    print(f\"Frase: '{frase}' ‚Üí Predicci√≥n: {etiquetas[pred]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iH4roY1dy27B","executionInfo":{"status":"ok","timestamp":1749678002037,"user_tz":-120,"elapsed":18925,"user":{"displayName":"Daniel Linfon Ye Liu","userId":"04630746813985450145"}},"outputId":"5ca3d924-87f3-4448-d23d-7203bb0785be"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Frase: 'Add this song to my playlist' ‚Üí Predicci√≥n: add\n","Frase: 'Could you remove this track?' ‚Üí Predicci√≥n: remove\n","Frase: 'Show me my current playlist' ‚Üí Predicci√≥n: view\n","Frase: 'Clear the entire playlist' ‚Üí Predicci√≥n: clear\n","Frase: 'Add this song to my playlist' ‚Üí Predicci√≥n: add\n","Frase: 'Remove this track from my list' ‚Üí Predicci√≥n: remove\n","Frase: 'Show me my current playlist' ‚Üí Predicci√≥n: view\n","Frase: 'Clear my entire playlist' ‚Üí Predicci√≥n: clear\n","Frase: 'Could you please delete all the songs?' ‚Üí Predicci√≥n: clear\n","Frase: 'Can you add a song to my playlist?' ‚Üí Predicci√≥n: add\n","Frase: 'I'd like to see what songs I have added' ‚Üí Predicci√≥n: view\n","Frase: 'Take this song out of my list' ‚Üí Predicci√≥n: remove\n","Frase: 'Hey, can u clear my playlist' ‚Üí Predicci√≥n: clear\n","Frase: 'can u delete the song Crazy' ‚Üí Predicci√≥n: remove\n"]}]},{"cell_type":"code","source":["# Cargar el modelo y el tokenizador\n","model_path = \"/content/drive/MyDrive/TFG/models/finetuned_t5-small_eval_loss\"\n","model = T5ForConditionalGeneration.from_pretrained(model_path)\n","tokenizer = T5TokenizerFast.from_pretrained(model_path)\n","\n","# Lista de frases de prueba\n","frases_prueba = [\n","    \"Add this song to my playlist\",  # ADD\n","    \"Could you remove this track?\",  # REMOVE\n","    \"Show me my current playlist\",  # VIEW\n","    \"Clear the entire playlist\",    # CLEAR\n","    \"Remove this track from my list\",  # REMOVE\n","    \"Show me my current playlist\",  # VIEW\n","    \"Clear my entire playlist\",  # CLEAR\n","    \"Could you please delete all the songs?\",  # CLEAR\n","    \"Can you add a song to my playlist?\",  # ADD\n","    \"I'd like to see what songs I have added\",  # VIEW\n","    \"Take this song out of my list\",  # REMOVE\n","    \"Hey, can u clear my playlist\",     # CLEAR\n","    \"can u delete the song Crazy\",   # REMOVE\n","]\n","\n","# Preprocesar y generar predicciones para cada frase\n","for frase in frases_prueba:\n","    # Preprocesar la entrada\n","    input_ids = tokenizer(\"Clasifica: \" + frase, return_tensors=\"pt\").input_ids\n","    attention_mask = tokenizer(\"Clasifica: \" + frase, return_tensors=\"pt\").attention_mask\n","\n","    # Generar la predicci√≥n\n","    model.eval()\n","    with torch.no_grad():\n","        generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=10)\n","\n","    # Decodificar la predicci√≥n\n","    decoded_pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","    # Imprimir la predicci√≥n\n","    print(f\"Frase: {frase}\")\n","    print(f\"Predicci√≥n: {decoded_pred}\")\n","    print(\"-\" * 50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749572444023,"user_tz":-120,"elapsed":5168,"user":{"displayName":"Daniel Linfon Ye Liu","userId":"04630746813985450145"}},"outputId":"08dcf1c3-7e09-418b-99d4-4af6b1bdcda5","id":"KAIj--RNzBJI"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Frase: Add this song to my playlist\n","Predicci√≥n: add\n","--------------------------------------------------\n","Frase: Could you remove this track?\n","Predicci√≥n: remove\n","--------------------------------------------------\n","Frase: Show me my current playlist\n","Predicci√≥n: view\n","--------------------------------------------------\n","Frase: Clear the entire playlist\n","Predicci√≥n: clear\n","--------------------------------------------------\n","Frase: Remove this track from my list\n","Predicci√≥n: clear\n","--------------------------------------------------\n","Frase: Show me my current playlist\n","Predicci√≥n: view\n","--------------------------------------------------\n","Frase: Clear my entire playlist\n","Predicci√≥n: clear\n","--------------------------------------------------\n","Frase: Could you please delete all the songs?\n","Predicci√≥n: clear\n","--------------------------------------------------\n","Frase: Can you add a song to my playlist?\n","Predicci√≥n: add\n","--------------------------------------------------\n","Frase: I'd like to see what songs I have added\n","Predicci√≥n: view\n","--------------------------------------------------\n","Frase: Take this song out of my list\n","Predicci√≥n: remove\n","--------------------------------------------------\n","Frase: Hey, can u clear my playlist\n","Predicci√≥n: clear\n","--------------------------------------------------\n","Frase: can u delete the song Crazy\n","Predicci√≥n: remove\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["# Cargar el modelo y el tokenizador desde el directorio guardado\n","model_path = \"/content/drive/MyDrive/TFG/models/finetuned_t5-small_eval_loss\"\n","model = T5ForConditionalGeneration.from_pretrained(model_path)\n","tokenizer = T5TokenizerFast.from_pretrained(model_path)\n","\n","input_text = \"can u delete the song Crazy\"\n","\n","# Preprocesar la entrada a√±adiendo el prefijo necesario\n","input_ids = tokenizer(\"Clasifica: \" + input_text, return_tensors=\"pt\").input_ids\n","attention_mask = tokenizer(\"Clasifica: \" + input_text, return_tensors=\"pt\").attention_mask\n","\n","# Generar la predicci√≥n\n","model.eval()  # Asegurarse de que el modelo est√© en modo de evaluaci√≥n\n","with torch.no_grad():  # No necesitamos gradientes para la inferencia\n","    generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=10)\n","\n","# Decodificar la predicci√≥n\n","decoded_pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","print(f\"Predicci√≥n: {decoded_pred}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zKBLbeDBzQDz","executionInfo":{"status":"ok","timestamp":1749572399644,"user_tz":-120,"elapsed":2425,"user":{"displayName":"Daniel Linfon Ye Liu","userId":"04630746813985450145"}},"outputId":"bcd51aba-f585-40dd-857a-90bd74e1aeb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicci√≥n: remove\n"]}]}]}